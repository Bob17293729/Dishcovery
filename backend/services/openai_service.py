"""
OpenAI æœåŠ¡æ¨¡å—
æä¾›å›¾ç‰‡å‹ç¼©ã€Markdownæå–ã€NDJSONè§£æç­‰æ ¸å¿ƒåŠŸèƒ½
æ”¯æŒä¸¤é˜¶æ®µæµå¼å¤„ç†ï¼šå›¾ç‰‡â†’Markdownâ†’NDJSON
"""
import openai
import os
import base64
import time
import io
import json
import asyncio
from typing import AsyncGenerator, Dict, Any, Tuple
from queue import Queue, Empty
from dotenv import load_dotenv
from PIL import Image

load_dotenv()

# ============================================================================
# å¸¸é‡å®šä¹‰
# ============================================================================

# ç¬¬ä¸€é˜¶æ®µï¼šå›¾ç‰‡ â†’ Markdown çš„ System Prompt
MARKDOWN_EXTRACTION_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€åä¸“ä¸šçš„èœå•æ–‡æœ¬æå–ä¸“å®¶ã€‚

ä½ çš„ä»»åŠ¡æ˜¯å°†èœå•å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡æœ¬å†…å®¹å®Œæ•´ã€å‡†ç¡®åœ°æå–ä¸º Markdown æ ¼å¼ã€‚

ã€æ ¸å¿ƒè¦æ±‚ã€‘
1. å®Œæ•´æå–æ‰€æœ‰æ–‡æœ¬ï¼ŒåŒ…æ‹¬ï¼š
   - èœå“åç§°ï¼ˆè‹±æ–‡ï¼‰
   - èœå“æè¿°ï¼ˆè‹±æ–‡ï¼‰
   - åˆ†ç±»æ ‡é¢˜ï¼ˆå¦‚ Salads, Pizzas, Desserts ç­‰ï¼‰
   - ä»·æ ¼ä¿¡æ¯
   - å°å­—è¯´æ˜ã€å¤‡æ³¨ç­‰

2. ä¿æŒåŸå§‹æ’ç‰ˆç»“æ„ï¼š
   - ä½¿ç”¨ Markdown æ ‡é¢˜ï¼ˆ# ## ###ï¼‰è¡¨ç¤ºåˆ†ç±»
   - ä½¿ç”¨åˆ—è¡¨æˆ–æ®µè½è¡¨ç¤ºèœå“
   - ä¿ç•™ç¼©è¿›å’Œä¸¤åˆ—æ’ç‰ˆä¿¡æ¯
   - ä½¿ç”¨é€‚å½“çš„ Markdown æ ¼å¼ï¼ˆ**ç²—ä½“**ã€*æ–œä½“*ç­‰ï¼‰

3. è¾“å‡ºè¦æ±‚ï¼š
   - ç›´æ¥è¾“å‡º Markdownï¼Œä¸è¦æ·»åŠ è§£é‡Šæ–‡å­—
   - ä¸è¦ä½¿ç”¨ä»£ç å—åŒ…è£¹
   - ç¡®ä¿æ‰€æœ‰æ–‡æœ¬éƒ½è¢«æå–ï¼Œä¸è¦é—æ¼ä»»ä½•å†…å®¹

4. æ ¼å¼ç¤ºä¾‹ï¼š
   # Menu
   
   ## Salads
   - **Caesar Salad** - Fresh romaine lettuce with Caesar dressing
   - **Chop Salad** - Mixed greens with vegetables
   
   ## Pizzas
   - **Margherita Pizza** - Classic tomato, mozzarella, and basil
   - **Pepperoni Pizza** - Spicy pepperoni with mozzarella
"""

# ç¬¬äºŒé˜¶æ®µï¼šMarkdown â†’ NDJSON çš„ System Prompt
NDJSON_GENERATION_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€åèœå•ç»“æ„åŒ–è§£æä¸“å®¶ã€‚

ä½ å¿…é¡»ä¸¥æ ¼æŒ‰"NDJSONï¼ˆä¸€è¡Œä¸€ä¸ª JSONï¼‰"æ ¼å¼è¾“å‡ºèœå“ä¿¡æ¯ã€‚

ã€æ ¸å¿ƒè¦æ±‚ã€‘
æ¯è¯†åˆ«åˆ°ä¸€é“èœï¼Œå°±ç«‹å³è¾“å‡ºä¸€è¡Œ JSONï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{"section": "...", "name_en": "...", "name_zh": "...", "ingredients_en": "...", "ingredients_zh": "...", "description_zh": "...", "image_prompt": "..."}

ä¸ç­‰å¾…å…¨éƒ¨èœè¯†åˆ«å®Œæˆã€‚

ã€å­—æ®µè¯´æ˜ã€‘
- section: èœå“æ‰€å±åˆ†ç±»ï¼ˆå¦‚ "Salads", "Pizzas", "Desserts"ï¼‰
- name_en: å®Œæ•´çš„è‹±æ–‡èœåï¼ˆå¿…é¡»è¡¥å…¨ï¼‰
- name_zh: è‡ªç„¶çš„ä¸­æ–‡ç¿»è¯‘
- ingredients_en: ä¸»è¦é£Ÿæåˆ—è¡¨ï¼ˆè‹±æ–‡ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚ "tomato, mozzarella, basil"ï¼‰
- ingredients_zh: ä¸»è¦é£Ÿæåˆ—è¡¨ï¼ˆä¸­æ–‡ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚ "ç•ªèŒ„, é©¬è‹é‡Œæ‹‰å¥¶é…ª, ç½—å‹’"ï¼‰
- description_zh: èœå“çš„ä¸­æ–‡è¯¦ç»†æè¿°ï¼ˆ80-120å­—ï¼ŒåŒ…å«å£æ„Ÿã€ç‰¹è‰²ã€åˆ¶ä½œæ–¹å¼ç­‰ï¼‰
- image_prompt: ç”¨äºç”Ÿæˆèœå“å›¾ç‰‡çš„è‹±æ–‡æç¤ºè¯ï¼ˆç®€æ´æè¿°èœå“å¤–è§‚ï¼Œå¦‚ "A beautiful Margherita pizza with fresh mozzarella, tomato sauce, and basil leaves on a wooden board"ï¼‰

ã€ç»“æ„è¡¥å…¨è§„åˆ™ã€‘
- å¦‚æœèœåä¸å®Œæ•´ï¼Œæ ¹æ® section è‡ªåŠ¨è¡¥å…¨ï¼š
  - "Salads" åŒºåŸŸä¸­çš„ "Chop" â†’ "Chop Salad"
  - "Pizzas" åŒºåŸŸä¸­çš„ "Margherita" â†’ "Margherita Pizza"
  - "Desserts" åŒºåŸŸä¸­çš„ "Cheesecake" â†’ "Cheesecake"
- å¦‚æœèœåå·²åŒ…å«ç±»åˆ«è¯ï¼ˆå¦‚ "Caesar Salad"ï¼‰ï¼Œä¸è¦é‡å¤è¡¥å…¨
- ç¡®ä¿ name_en æ˜¯å®Œæ•´ã€è§„èŒƒçš„èœå

ã€å­—æ®µç”Ÿæˆè¦æ±‚ã€‘
- ingredients_en å’Œ ingredients_zhï¼šä»èœå•ä¸­æå–ä¸»è¦é£Ÿæï¼Œå¦‚æœæ²¡æœ‰æ˜ç¡®åˆ—å‡ºï¼Œæ ¹æ®èœåæ¨æ–­
- description_zhï¼šåŸºäºèœå•ä¸­çš„æè¿°ä¿¡æ¯ï¼Œç”Ÿæˆä¸“ä¸šã€è‡ªç„¶çš„ä¸­æ–‡èœå“ä»‹ç»ï¼ŒåŒ…å«å£æ„Ÿã€ç‰¹è‰²ã€åˆ¶ä½œæ–¹å¼ç­‰
- image_promptï¼šç”Ÿæˆç®€æ´çš„è‹±æ–‡æç¤ºè¯ï¼Œæè¿°èœå“çš„å¤–è§‚ç‰¹å¾ï¼Œç”¨äº AI å›¾ç‰‡ç”Ÿæˆ

ã€è¾“å‡ºè§„åˆ™ã€‘
- ç»å¯¹ç¦æ­¢è¾“å‡ºæ•°ç»„ã€åŒ…è£¹çš„å¤§ JSON
- ç»å¯¹ç¦æ­¢è¾“å‡º markdown æ ¼å¼ã€æ³¨é‡Šã€è§£é‡Šæ–‡å­—
- ç»å¯¹ç¦æ­¢ä½¿ç”¨ ```json ä»£ç å—
- æ¯ä¸€è¡Œå¿…é¡»æ˜¯åˆæ³•çš„ JSON å¯¹è±¡
- ä¸€è¡Œ = ä¸€é“èœ
- ç«‹å³è¾“å‡ºï¼Œä¸è¦ç­‰å¾…
- æ‰€æœ‰å­—æ®µéƒ½å¿…é¡»æœ‰å€¼ï¼ˆå³ä½¿æ˜¯ç©ºå­—ç¬¦ä¸²ï¼‰
"""

# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def compress_image(image_bytes: bytes) -> Tuple[bytes, str]:
    """
    å‹ç¼©å›¾ç‰‡ä¸º JPEG æ ¼å¼
    
    Args:
        image_bytes: åŸå§‹å›¾ç‰‡å­—èŠ‚
        
    Returns:
        (å‹ç¼©åçš„å­—èŠ‚, å›¾ç‰‡æ ¼å¼)
    """
    try:
        img = Image.open(io.BytesIO(image_bytes))
        original_size = img.size
        
        # å¦‚æœæœ€é•¿è¾¹è¶…è¿‡ 2000pxï¼Œè¿›è¡Œç¼©æ”¾
        if max(img.size) > 2000:
            scale = 2000 / max(img.size)
            new_size = (int(img.size[0] * scale), int(img.size[1] * scale))
            img = img.resize(new_size, Image.Resampling.LANCZOS)
            print(f"ğŸ“ å›¾ç‰‡ç¼©æ”¾: {original_size} â†’ {new_size}")
        
        # è½¬æ¢ä¸º RGB æ¨¡å¼ï¼ˆJPEG ä¸æ”¯æŒé€æ˜é€šé“ï¼‰
        if img.mode != "RGB":
            img = img.convert("RGB")
        
        # ä¿å­˜ä¸º JPEGï¼Œè´¨é‡ 85
        buf = io.BytesIO()
        img.save(buf, format="JPEG", quality=85, optimize=True)
        compressed_bytes = buf.getvalue()
        
        print(f"ğŸ“ å›¾ç‰‡å‹ç¼©: {len(image_bytes)} bytes â†’ {len(compressed_bytes)} bytes")
        return compressed_bytes, "jpeg"
    except Exception as e:
        print(f"âš ï¸ å›¾ç‰‡å‹ç¼©å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾: {e}")
        return image_bytes, "jpeg"


def extract_text_from_delta(delta) -> str:
    """
    ä» OpenAI delta å¯¹è±¡ä¸­æå–æ–‡æœ¬å†…å®¹
    å…¼å®¹å¤šç§ delta.content ç±»å‹ï¼šstrã€listã€dict
    
    Args:
        delta: OpenAI å“åº”ä¸­çš„ delta å¯¹è±¡
        
    Returns:
        æå–çš„æ–‡æœ¬å­—ç¬¦ä¸²
    """
    if not hasattr(delta, "content"):
        return ""
    
    data = delta.content
    if isinstance(data, str):
        return data
    elif isinstance(data, list):
        texts = []
        for item in data:
            if isinstance(item, str):
                texts.append(item)
            elif isinstance(item, dict) and "text" in item:
                texts.append(item["text"])
        return "".join(texts)
    return ""


# ============================================================================
# OpenAI æœåŠ¡ç±»
# ============================================================================

class OpenAIService:
    """OpenAI API æœåŠ¡å°è£…ç±»"""
    
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is not set")
        self.client = openai.OpenAI(api_key=api_key)

    async def analyze_menu_image_stream(
        self, 
        image_bytes: bytes
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        ä¸¤é˜¶æ®µæµå¼å¤„ç†ï¼šå›¾ç‰‡ â†’ Markdown â†’ NDJSON
        
        ç¬¬ä¸€é˜¶æ®µï¼šæµå¼è¾“å‡º Markdownï¼ˆyield {"type": "markdown", "content": "..."}ï¼‰
        ç¬¬äºŒé˜¶æ®µï¼šæµå¼è¾“å‡º NDJSON èœå“ï¼ˆyield {"type": "dish", "dish": {...}}ï¼‰
        
        Args:
            image_bytes: èœå•å›¾ç‰‡çš„å­—èŠ‚æ•°æ®
            
        Yields:
            - {"type": "markdown", "content": "..."} - Markdown æ–‡æœ¬ç‰‡æ®µ
            - {"type": "markdown_done"} - Markdown é˜¶æ®µå®Œæˆ
            - {"type": "dish", "dish": {...}} - èœå“ JSON å¯¹è±¡
            - {"type": "done"} - å…¨éƒ¨å®Œæˆ
        """
        start_time = time.time()
        print(f"ğŸ–¼ å¼€å§‹å¤„ç†å›¾ç‰‡: {len(image_bytes)} bytes")
        
        # 1. å‹ç¼©å›¾ç‰‡
        compressed_bytes, image_format = compress_image(image_bytes)
        base64_image = base64.b64encode(compressed_bytes).decode("utf-8")
        
        # 2. ç¬¬ä¸€é˜¶æ®µï¼šå›¾ç‰‡ â†’ Markdownï¼ˆæµå¼ï¼‰
        print("ğŸ“ é˜¶æ®µ1: å¼€å§‹æå– Markdown...")
        markdown_content = ""
        
        async for chunk in self._stream_markdown_extraction(base64_image, image_format):
            if chunk["type"] == "markdown":
                markdown_content += chunk["content"]
                yield chunk  # å®æ—¶è¾“å‡º Markdown ç‰‡æ®µ
            elif chunk["type"] == "error":
                yield chunk
                return
        
        yield {"type": "markdown_done"}
        print(f"âœ… Markdown æå–å®Œæˆï¼Œé•¿åº¦: {len(markdown_content)} å­—ç¬¦")
        
        # 3. ç¬¬äºŒé˜¶æ®µï¼šMarkdown â†’ NDJSONï¼ˆæµå¼ï¼‰
        if not markdown_content.strip():
            yield {"type": "error", "error": "æœªèƒ½æå–åˆ° Markdown å†…å®¹"}
            return
        
        print("ğŸ½ é˜¶æ®µ2: å¼€å§‹è§£æ NDJSON...")
        dish_count = 0
        
        async for chunk in self._stream_ndjson_generation(markdown_content):
            if chunk["type"] == "dish":
                dish_count += 1
                print(f"   â†’ æ”¶åˆ°èœå“ {dish_count}: {chunk['dish']['name_en']}")
                yield chunk
            elif chunk["type"] == "error":
                yield chunk
                return
        
        yield {"type": "done"}
        elapsed = time.time() - start_time
        print(f"ğŸ‰ å¤„ç†å®Œæˆï¼š{dish_count} é“èœï¼Œæ€»è€—æ—¶ {elapsed:.2f}s")

    async def _stream_markdown_extraction(
        self, 
        base64_image: str, 
        image_format: str
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        ç¬¬ä¸€é˜¶æ®µï¼šæµå¼æå– Markdown
        
        Args:
            base64_image: Base64 ç¼–ç çš„å›¾ç‰‡
            image_format: å›¾ç‰‡æ ¼å¼
            
        Yields:
            {"type": "markdown", "content": "..."} æˆ– {"type": "error", "error": "..."}
        """
        loop = asyncio.get_event_loop()
        chunk_queue = Queue()
        
        def create_stream(queue):
            """åœ¨åå°çº¿ç¨‹ä¸­åˆ›å»ºæµ"""
            try:
                stream = self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": MARKDOWN_EXTRACTION_SYSTEM_PROMPT},
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": "è¯·å®Œæ•´æå–è¿™å¼ èœå•å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡æœ¬å†…å®¹ï¼Œè¾“å‡ºä¸º Markdown æ ¼å¼ã€‚"},
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/{image_format};base64,{base64_image}"
                                    }
                                }
                            ]
                        }
                    ],
                    stream=True,
                    max_tokens=4096
                )
                
                for chunk in stream:
                    queue.put(chunk)
                queue.put(None)  # ç»“æŸæ ‡è®°
            except Exception as e:
                queue.put(e)  # é”™è¯¯æ ‡è®°
        
        executor = loop.run_in_executor(None, create_stream, chunk_queue)
        
        try:
            while True:
                def get_chunk():
                    try:
                        return chunk_queue.get(timeout=0.1)
                    except Empty:
                        return None
                
                chunk = await loop.run_in_executor(None, get_chunk)
                
                if chunk is None:
                    if executor.done():
                        try:
                            executor.result()
                        except Exception as e:
                            yield {"type": "error", "error": str(e)}
                            return
                        if chunk_queue.empty():
                            break
                    await asyncio.sleep(0.01)
                    continue
                
                if isinstance(chunk, Exception):
                    yield {"type": "error", "error": str(chunk)}
                    return
                
                if not chunk.choices:
                    continue
                
                delta = chunk.choices[0].delta
                if not delta:
                    continue
                
                text = extract_text_from_delta(delta)
                if text:
                    yield {"type": "markdown", "content": text}
                
                await asyncio.sleep(0)
        except Exception as e:
            yield {"type": "error", "error": f"Markdown æå–å¤±è´¥: {str(e)}"}

    async def _stream_ndjson_generation(
        self, 
        markdown_content: str
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        ç¬¬äºŒé˜¶æ®µï¼šæµå¼ç”Ÿæˆ NDJSON
        
        Args:
            markdown_content: å®Œæ•´çš„ Markdown å†…å®¹
            
        Yields:
            {"type": "dish", "dish": {...}} æˆ– {"type": "error", "error": "..."}
        """
        loop = asyncio.get_event_loop()
        chunk_queue = Queue()
        
        def create_stream(queue):
            """åœ¨åå°çº¿ç¨‹ä¸­åˆ›å»ºæµ"""
            try:
                stream = self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": NDJSON_GENERATION_SYSTEM_PROMPT},
                        {
                            "role": "user",
                            "content": f"è¯·åˆ†æä»¥ä¸‹èœå• Markdownï¼ŒæŒ‰ NDJSON æ ¼å¼é€æ¡è¾“å‡ºèœå“ä¿¡æ¯ï¼š\n\n{markdown_content}"
                        }
                    ],
                    stream=True,
                    max_tokens=4096
                )
                
                for chunk in stream:
                    queue.put(chunk)
                queue.put(None)  # ç»“æŸæ ‡è®°
            except Exception as e:
                queue.put(e)  # é”™è¯¯æ ‡è®°
        
        executor = loop.run_in_executor(None, create_stream, chunk_queue)
        
        buffer = ""
        
        try:
            while True:
                def get_chunk():
                    try:
                        return chunk_queue.get(timeout=0.1)
                    except Empty:
                        return None
                
                chunk = await loop.run_in_executor(None, get_chunk)
                
                if chunk is None:
                    if executor.done():
                        try:
                            executor.result()
                        except Exception as e:
                            yield {"type": "error", "error": str(e)}
                            return
                        if chunk_queue.empty():
                            break
                    await asyncio.sleep(0.01)
                    continue
                
                if isinstance(chunk, Exception):
                    yield {"type": "error", "error": str(chunk)}
                    return
                
                if not chunk.choices:
                    continue
                
                delta = chunk.choices[0].delta
                if not delta:
                    continue
                
                text = extract_text_from_delta(delta)
                if not text:
                    continue
                
                buffer += text
                
                # æŒ‰è¡Œæ‹†åˆ†å¹¶è§£æ JSON
                while "\n" in buffer:
                    line, buffer = buffer.split("\n", 1)
                    line = line.strip()
                    
                    # è·³è¿‡ç©ºè¡Œå’Œé JSON è¡Œ
                    if not line or not line.startswith("{") or not line.endswith("}"):
                        continue
                    
                    try:
                        data = json.loads(line)
                        
                        # æ ¼å¼åŒ–èœå“ç»“æ„ï¼ˆæ–°å­—æ®µç»“æ„ï¼‰
                        dish = {
                            "section": data.get("section", ""),
                            "name_en": data.get("name_en", ""),
                            "name_zh": data.get("name_zh", ""),
                            "ingredients_en": data.get("ingredients_en", ""),
                            "ingredients_zh": data.get("ingredients_zh", ""),
                            "description_zh": data.get("description_zh", ""),
                            "image_prompt": data.get("image_prompt", ""),
                        }
                        
                        yield {"type": "dish", "dish": dish}
                    except json.JSONDecodeError:
                        # å¿½ç•¥è§£æå¤±è´¥çš„ JSON
                        continue
                
                await asyncio.sleep(0)
            
            # å¤„ç† buffer ä¸­æœ€åå¯èƒ½æ®‹ç•™çš„ä¸€è¡Œ
            if buffer.strip().startswith("{") and buffer.strip().endswith("}"):
                try:
                    data = json.loads(buffer.strip())
                    dish = {
                        "section": data.get("section", ""),
                        "name_en": data.get("name_en", ""),
                        "name_zh": data.get("name_zh", ""),
                        "ingredients_en": data.get("ingredients_en", ""),
                        "ingredients_zh": data.get("ingredients_zh", ""),
                        "description_zh": data.get("description_zh", ""),
                        "image_prompt": data.get("image_prompt", ""),
                    }
                    yield {"type": "dish", "dish": dish}
                except json.JSONDecodeError:
                    pass
        except Exception as e:
            yield {"type": "error", "error": f"NDJSON ç”Ÿæˆå¤±è´¥: {str(e)}"}

    async def get_dish_description_stream(
        self, 
        dish_name: str, 
        translation: str = None, 
        menu_description: str = None, 
        translation_description: str = None
    ) -> AsyncGenerator[str, None]:
        """
        æµå¼è·å–å•ä¸ªèœå“çš„è¯¦ç»†æè¿°
        
        Args:
            dish_name: è‹±æ–‡èœå
            translation: ä¸­æ–‡ç¿»è¯‘
            menu_description: èœå•ä¸­çš„è‹±æ–‡æè¿°
            translation_description: èœå•ä¸­çš„ä¸­æ–‡æè¿°
            
        Yields:
            æè¿°æ–‡æœ¬ç‰‡æ®µï¼ˆé€ä¸ª tokenï¼‰
        """
        start_time = time.time()
        prompt = f"""è¯·ä¸ºä»¥ä¸‹èœå“æä¾›è¯¦ç»†æè¿°ï¼ˆ80-120å­—ï¼‰ï¼š
èœå“åç§°ï¼š{dish_name}"""
        
        if translation:
            prompt += f"\nä¸­æ–‡åç§°ï¼š{translation}"
        
        if translation_description:
            prompt += f"\nèœå•æè¿°ï¼ˆä¸­æ–‡ï¼‰ï¼š{translation_description}"
        elif menu_description:
            prompt += f"\nèœå•æè¿°ï¼ˆè‹±æ–‡ï¼‰ï¼š{menu_description}"
        
        prompt += "\n\nè¦æ±‚ï¼š"
        prompt += "\n1. åŸºäºèœå•ä¸­çš„æè¿°ä¿¡æ¯ï¼Œç”Ÿæˆä¸“ä¸šã€è‡ªç„¶çš„ä¸­æ–‡èœå“ä»‹ç»"
        prompt += "\n2. ä¸è¦é€å­—ç¿»è¯‘ï¼Œè¦ç†è§£èœå“ç‰¹ç‚¹åé‡æ–°ç»„ç»‡è¯­è¨€"
        prompt += "\n3. å¯ä»¥é€‚å½“è¡¥å……èœå“çš„ç‰¹è‰²ã€å£æ„Ÿã€åˆ¶ä½œæ–¹å¼ç­‰ä¿¡æ¯"
        prompt += "\n4. è¯­è¨€è¦æµç•…ï¼Œè®©ä¸­æ–‡è¯»è€…èƒ½å¤Ÿç†è§£å¹¶äº§ç”Ÿé£Ÿæ¬²"
        prompt += "\n5. æè¿°é•¿åº¦åœ¨80-120å­—ä¹‹é—´"

        try:
            print(f"ğŸ“ å¼€å§‹æµå¼ç”Ÿæˆèœå“æè¿°: {dish_name}")
            loop = asyncio.get_event_loop()
            chunk_queue = Queue()
            
            def create_stream(queue):
                """åœ¨åå°çº¿ç¨‹ä¸­åˆ›å»ºæµ"""
                try:
                    stream = self.client.chat.completions.create(
                model="gpt-4o-mini",
                        messages=[{"role": "user", "content": prompt}],
                        stream=True,
                max_tokens=300
            )
            
                    for chunk in stream:
                        queue.put(chunk)
                    queue.put(None)  # ç»“æŸæ ‡è®°
                except Exception as e:
                    queue.put(e)  # é”™è¯¯æ ‡è®°
            
            executor = loop.run_in_executor(None, create_stream, chunk_queue)
            
            try:
                while True:
                    def get_chunk():
                        try:
                            return chunk_queue.get(timeout=0.1)
                        except Empty:
                            return None
                    
                    chunk = await loop.run_in_executor(None, get_chunk)
                    
                    if chunk is None:
                        if executor.done():
                            try:
                                executor.result()
                            except Exception as e:
                                print(f"âŒ æè¿°ç”Ÿæˆå¤±è´¥: {e}")
                                yield f"æè¿°ç”Ÿæˆå¤±è´¥: {str(e)}"
                                return
                            if chunk_queue.empty():
                                break
                        await asyncio.sleep(0.01)
                        continue
                    
                    if isinstance(chunk, Exception):
                        print(f"âŒ æè¿°ç”Ÿæˆå¤±è´¥: {chunk}")
                        yield f"æè¿°ç”Ÿæˆå¤±è´¥: {str(chunk)}"
                        return
                    
                    if not chunk.choices:
                        continue
                    
                    delta = chunk.choices[0].delta
                    if not delta:
                        continue
                    
                    text = extract_text_from_delta(delta)
                    if text:
                        yield text
                    
                    await asyncio.sleep(0)
                
                elapsed = time.time() - start_time
                print(f"âœ… æè¿°ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶ {elapsed:.2f}s")
            except Exception as e:
                print(f"âŒ æè¿°ç”Ÿæˆå¤±è´¥: {e}")
                yield f"æè¿°ç”Ÿæˆå¤±è´¥: {str(e)}"
        except Exception as e:
            print(f"âŒ æè¿°ç”Ÿæˆå¤±è´¥: {e}")
            yield f"æè¿°ç”Ÿæˆå¤±è´¥: {str(e)}"

    async def generate_dish_image(self, image_prompt: str) -> str:
        """
        ä½¿ç”¨ DALL-E ç”Ÿæˆèœå“å›¾ç‰‡
        
        Args:
            image_prompt: å›¾ç‰‡ç”Ÿæˆæç¤ºè¯ï¼ˆè‹±æ–‡ï¼‰
            
        Returns:
            ç”Ÿæˆçš„å›¾ç‰‡ URL
        """
        start_time = time.time()
        
        # ä½¿ç”¨ä¼ å…¥çš„ image_promptï¼Œå¹¶æ·»åŠ é€šç”¨ä¿®é¥°è¯
        prompt = f"{image_prompt}, professional food photography, high quality, restaurant style"
        
        try:
            print(f"ğŸ¨ å¼€å§‹ç”Ÿæˆå›¾ç‰‡ï¼Œæç¤ºè¯: {image_prompt[:50]}...")
            response = self.client.images.generate(
                model="dall-e-3",
                prompt=prompt,
                size="1024x1024",
                quality="standard",
                n=1
            )
            
            if not response.data or len(response.data) == 0:
                raise Exception("å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼šæœªè¿”å›å›¾ç‰‡URL")
            
            elapsed = time.time() - start_time
            print(f"âœ… å›¾ç‰‡ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶ {elapsed:.2f}s")
            return response.data[0].url
        except Exception as e:
            raise Exception(f"DALL-Eå›¾ç‰‡ç”Ÿæˆå¤±è´¥: {str(e)}")
