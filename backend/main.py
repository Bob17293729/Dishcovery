from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional
import os
import json
import asyncio
from dotenv import load_dotenv

from services.openai_service import OpenAIService

load_dotenv()

app = FastAPI(title="Dishcovery API")

# CORSé…ç½® - å…è®¸æ‰€æœ‰æ¥æºï¼ˆå¼€å‘ç¯å¢ƒï¼‰
# ç”Ÿäº§ç¯å¢ƒå»ºè®®é™åˆ¶ä¸ºç‰¹å®šåŸŸå
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å…è®¸æ‰€æœ‰æ¥æºï¼Œæ–¹ä¾¿ç§»åŠ¨ç«¯è®¿é—®
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–OpenAIæœåŠ¡
openai_service = OpenAIService()


class GenerateImageRequest(BaseModel):
    image_prompt: str


@app.get("/")
async def root():
    return {"message": "Dishcovery API is running"}


@app.post("/api/analyze-menu")
async def analyze_menu(file: UploadFile = File(...)):
    """
    åˆ†æèœå•å›¾ç‰‡ï¼Œä¸¤é˜¶æ®µæµå¼è¿”å›ï¼š
    1. ç¬¬ä¸€é˜¶æ®µï¼šMarkdown æµå¼è¾“å‡º
    2. ç¬¬äºŒé˜¶æ®µï¼šNDJSON èœå“æµå¼è¾“å‡º
    ä½¿ç”¨ Server-Sent Events (SSE) æ ¼å¼
    """
    async def generate():
        try:
            print(f"ğŸ“¥ æ”¶åˆ°å›¾ç‰‡ä¸Šä¼ è¯·æ±‚: {file.filename}, ç±»å‹: {file.content_type}")
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            print("ğŸ“– å¼€å§‹è¯»å–æ–‡ä»¶å†…å®¹...")
            contents = await file.read()
            print(f"âœ… æ–‡ä»¶è¯»å–å®Œæˆï¼Œå¤§å°: {len(contents)} bytes")
            
            # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆé™åˆ¶ä¸º10MBï¼‰
            if len(contents) > 10 * 1024 * 1024:
                yield f"data: {json.dumps({'type': 'error', 'error': 'å›¾ç‰‡æ–‡ä»¶è¿‡å¤§ï¼Œè¯·ä¸Šä¼ å°äº10MBçš„å›¾ç‰‡'})}\n\n"
                return
            
            # è°ƒç”¨OpenAIæœåŠ¡è¿›è¡Œä¸¤é˜¶æ®µæµå¼å¤„ç†
            print("ğŸ¤– å¼€å§‹è°ƒç”¨OpenAI APIï¼ˆä¸¤é˜¶æ®µæµå¼ï¼‰...")
            
            async for chunk in openai_service.analyze_menu_image_stream(contents):
                # è½¬å‘æ‰€æœ‰ç±»å‹çš„æ¶ˆæ¯
                yield f"data: {json.dumps(chunk)}\n\n"
            
            print("âœ… æµå¼å¤„ç†å®Œæˆ")
            
        except Exception as e:
            import traceback
            error_detail = str(e)
            print(f"âŒ åˆ†æèœå•é”™è¯¯: {error_detail}")
            print(traceback.format_exc())
            yield f"data: {json.dumps({'type': 'error', 'error': f'åˆ†æèœå•å¤±è´¥: {error_detail}'})}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # ç¦ç”¨ nginx ç¼“å†²
        }
    )


@app.post("/api/generate-image")
async def generate_image(request: GenerateImageRequest):
    """
    æ ¹æ® image_prompt ç”Ÿæˆèœå“å‚è€ƒå›¾ç‰‡
    """
    try:
        image_url = await openai_service.generate_dish_image(request.image_prompt)
        return {"image_url": image_url}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {str(e)}")

